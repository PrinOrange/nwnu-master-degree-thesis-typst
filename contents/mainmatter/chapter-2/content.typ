#import "/components/codeblock.typ": code
#import "/components/table.typ": ntable, tltable
#import "/components/reasoning.typ": *
#import "/components/algorithm.typ": algorithm

#import "/templates/mainmatter.typ": mainmatter-template
#show: mainmatter-template

= 写作要求说明

在这一章，我们介绍内容元素的格式说明。

== 论文语言风格

除外国语言文学相关专业研究生及留学生（不含汉语国际教育硕士）外，学位论文一律须用汉语书写。学位论文应当用规范汉字进行撰写，除古汉语研究中涉及的古文字和参考文献中引用的外文文献之外，均采用简体汉字撰写。

留学生一般应以中文或英文书写学位论文，格式要求同上。论文须用中文封面。 学位论文是学术作品，因此其表述要严谨简明，重点突出，专业常识应简写或不写，做到层次分明、数据可靠、文字凝练、说明透彻、推理严谨、立论正确，避免使用文学性质的或带感情色彩的非学术性语言。

论文中的名称应当使用正式名称，可以参考全国科学技术名词审定委员会发布的专业术语 #footnote("全国科学技术审定委员会已发布的术语列表可以在该网址查看：http://www.cnterm.cn/cb/sdgb/") 论文中如出现一个非通用性的新名词、新术语或新概念，需随即解释清楚，如果有名词需要简写，则需要带上标注“以下简称”，例如全国科学技术名词审定委员会（以下简称“科技术语委”）的网站是 www.cnterm.cn 。

== 论文题目

论文题目应简明扼要地反映论文工作的主要内容，切忌笼统。由于读者要通过论文题目中的关键词来检索论文，所以用语准确非常重要。论文题目应该是对研究对象的准确具体的描述，这种描述要在一定程度上体现研究结论。因此，论文题目不仅应告诉读者这本论文研究了什么问题，更要告诉读者这个研究得出的结论。例如：“在事实与虚构之间：梅乐、卡彭特、沃尔夫的新闻观”就比“三个美国作家的新闻观研究”更专业更准确。

== 研究背景和意义

“研究背景和意义”旨在说明你的课题是如何从现实或学术问题中产生的、现有研究存在哪些不足，以及你的研究为什么值得做。一般会先介绍领域的发展现状，然后指出已有方法的局限或空白，最后强调你的研究在理论上能填补哪些缺口，在实践中能带来哪些应用价值。这部分是论文立论的基础，帮助读者理解你的工作为何重要、为何必要。下面给出一个例子。

随着人工智能与大数据技术的不断融合，基于深度学习的图神经网络（GNN）在社交网络分析、推荐系统等场景中展现出强大的建模能力。然而，现有 GNN 方法普遍面临着模型过度拟合、高阶邻居信息泛化能力不足等挑战，尤其在稀疏图数据中效果有限。针对这一问题，本文尝试从结构优化和邻居采样策略两个方向入手，提出一种改进的图卷积模型。该研究不仅有助于提升图神经网络在复杂数据环境下的表达能力，也为相关算法的可解释性研究提供理论支撑，具有重要的理论与实际意义。

== 国内外研究现状分析

“国内外研究现状”是学术论文中极其关键的部分，主要用于交代研究主题的发展背景、已有成果及其不足，从而为本文的研究动机和创新点打下基础。它不仅需要展示你对领域前沿的系统了解、梳理已有成果的脉络与贡献；还需要指出当前研究的不足、空白或争议；并从此引出你自己的研究问题或创新点。以下是范文。

=== 研究背景与问题概述
随着社交媒体、电子商务和信息服务的迅猛发展，个性化推荐技术逐渐成为解决信息过载的重要手段。其中，协同过滤作为主流推荐方法之一，在工业界和学术界得到了广泛研究。然而，传统方法往往难以捕捉用户行为中隐含的高阶语义关系，导致推荐性能下降。近年来，图神经网络（Graph Neural Networks, GNNs）的兴起为推荐系统建模提供了新的可能。

=== 国外研究现状
国外学者较早将图结构引入推荐建模。例如，Ying 等人（2018）提出了 PinSage，结合图结构和采样机制对 Pinterest 推荐任务进行建模；Wang 等人（2019）提出 NGCF 模型 #footnote("Wang, X., He, X., Wang, M., Feng, F., & Chua, T.-S. (2019). Neural graph collaborative filtering. Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (pp. 165–174). https://doi.org/10.1145/3331184.3331267") ，利用多层邻居传播机制挖掘高阶协同信息；随后，LightGCN、SGL 等轻量或对比学习增强的模型不断被提出，推动了图神经推荐的发展。

然而，现有 GNN 推荐模型仍面临以下问题：（1）多层图传播过程中节点表示易发生过度平滑；（2）模型复杂度较高，训练代价大；（3）对异构或动态图结构的建模能力不足。

=== 国内研究现状
国内在图推荐研究方面起步略晚，但近年来也取得了较多成果。清华大学、浙江大学、中科院等机构的学者围绕 NGCF 改进、多模态融合、对比学习等展开了系统研究。例如，某某（2021）提出了一种基于多任务学习的 GNN 推荐模型，在阿里数据集上获得较优表现。但总体而言，与国外相比仍存在一定差距，尤其在模型简化、泛化能力提升和真实工业部署方面尚需突破。

=== 存在的问题与研究空白
总体来看，当前图神经网络推荐研究存在如下不足：

1. 过拟合与过平滑现象尚未完全解决；
2. 大规模稀疏图下的训练效率仍需提升；
3. 缺乏对多源异构信息的统一建模机制；
4. 多数模型难以适配动态变化的推荐场景。

=== 本文研究切入点
针对上述问题，本文提出一种结构简洁、训练高效且具备高阶建模能力的图神经推荐模型，并在多个真实数据集上进行系统实验。相比已有方法，本文的研究具有如下特点：（1）引入轻量化残差传播结构缓解信息冗余；（2）设计对比增强机制提升泛化性能；（3）验证模型在动态图推荐中的鲁棒性。

== 图、表、公式、算法等的说明

=== 插图的说明

图要求清晰，最好为矢量图，图中文字最好用中文。

图要精选，具有自明性，切忌与表及文字表述重复。图要清楚，但坐标比例不要过分放大，同一图上不同曲线的点要分别用不同形状的标识符标出。地图插图涉及中国地图全图时，须使用自然资源部标准地图底图制作。

图序与图名置于图的下方，用宋体5号字，居中，段前空6磅，段后空12磅，单倍行距；图序与图名文字之间空一个字符。如“图2-1 发展中国家经济增长速度的比较（1960-2000）”，其中“图2.1”是图序。根据学科专业习惯可在中文图序和图名下方添加对应的英文图序和名，采用Times New Roman体，居中，段前空0磅，段后空12磅，单倍行距。

#figure(image("./figure-2-1.svg", width: 70%), caption: [这是一张示例插图])

图中的术语、符号、单位等应与正文表述中所用一致，图中文字用5号或小5 号（9～10.5 磅）字，以能够清晰阅读为标准。专用名字代号、单位可采用外文表示，坐标轴题名、词组、描述性的词语均须采用中文。

如果一个图由两个或两个以上分图组成时，各分图分别以(a)、(b)、(c)……作为图序，并须有分图名。

#figure(image("./figure-2-2.svg", width: 70%), caption: [这是一另张示例插图])

=== 列表的说明

=== 表的说明

表格一般应采用三线表（必要时可加辅助线），即表的上、下边线为单直线，线粗为1.5 磅，第三条线为单直线，线粗为1 磅。当三线表无法清晰表达时，可采用其他格式。

表中参数应标明量和单位的符号。表单元格中的文字一般用宋体5 号或小5号字，居中（上下、左右均居中），单倍行距，段前空3 磅，段后空3 磅。不宜左右居中时，可采取两端对齐的方式。

表序与表名置于表的上方，用宋体5 号字，居中，段前空12 磅，段后空6磅，单倍行距，表序与表名文字之间空一个字符。如“表3-1 XXX”，其中“表3.1”是表序。

#tltable("示例三线表")[
  | Substance | Subcritical °C | Supercritical °C |
  | --------------------- | -------------- | ---------------- |
  | Hydrochloric Acid | 12.0 | 92.1 |
  | Sodium Myreth Sulfate | 16.6 | 104 |
  | Potassium Hydroxide | 24.7 | < |
]

=== 代码的说明

论文中可以插入代码，代码有两种形式：代码块和行内代码。代码块支持市面上常用的编程语言，且支持高亮。

下面是一个 C语言 实现的标准二叉树中序遍历（inorder traversal） 的示例。

首先是二叉树节点结构定义，我们在 C 语言中定义结构体 `TreeNode`：

#code(linenumbers: true, caption: "TreeNode 定义")[```c
  #include <stdio.h>
  #include <stdlib.h>
  // 定义二叉树节点结构
  typedef struct TreeNode {
      int val;
      struct TreeNode* left;
      struct TreeNode* right;
  } TreeNode;
  ```]

然后实现代码中比较核心的部分：创建结点的辅助函数，以及中序遍历的递归实现。

#code(linenumbers: true, caption: "中序遍历与创建节点函数")[```c
  // 中序遍历函数（递归）
  void inorderTraversal(TreeNode* root) {
      if (root == NULL) return;
      inorderTraversal(root->left);         // 访问左子树
      printf("%d ", root->val);             // 访问当前节点
      inorderTraversal(root->right);        // 访问右子树
  }
  // 创建新节点的辅助函数
  TreeNode* createNode(int val) {
      TreeNode* node = (TreeNode*)malloc(sizeof(TreeNode));
      node->val = val;
      node->left = NULL;
      node->right = NULL;
      return node;
  }
  ```]

=== 公式的说明

论文公式有三种形式：行内公式、演算过程和结果公式。

行内公式和演算过程可以不用带编号，而“结果公式”作为在后文中可能因用到的公式，需要带上编号。公式编号规则为 (章节号-公式序号)。

以下面的正文举个例子：

比如，现在我想求出一元二次方程 $a x^2 + b x + c = 0, (a ≠ 0)$ 的求根公式，有以下演算过程：


$ a x^2 + b x + c = 0 ⇒ \
a x^2 + b x = -c ⇒ \
x^2 + frac(b, a)x = -frac(c, a) ⇒ \
x^2 + frac(b, a)x + (frac(b, 2a))^2 = -frac(c, a) + (frac(b, 2a))^2 ⇒ \
(x + frac(b, 2a))^2 = -frac(c, a) + frac(b^2, 4a^2) ⇒ \
(x + frac(b, 2a))^2 = frac(b^2 - 4a c, 4a^2) ⇒ \
x + frac(b, 2a) = plus.minus sqrt(frac(b^2 - 4a c, 4a^2)) ⇒ \
x + frac(b, 2a) = plus.minus frac(sqrt(b^2 - 4a c), 2a) ⇒ \
x = -frac(b, 2a) plus.minus frac(sqrt(b^2 - 4a c), 2a) ⇒ \ $,


最终，我们就得到了如下对一元二次方程的求根公式：


$ x = frac(-b plus.minus sqrt(b^2 - 4 a c), 2a) $,


=== 推理语言说明

公理（Axiom / Postulate）是不证自明的假设，是整个系统的基础前提。所有其他内容都以此为出发点进行推导。
定义（Definition）对某个概念的精确定义，不参与推理，只是为了引入术语和简化表达。
命题（Proposition）可被证明为真或假的陈述，通常用于描述不那么核心但仍重要的事实。
引理（Lemma）为证明更重要的定理所用的中间步骤或辅助命题。它本身可能不那么重要，但对整个推理链至关重要。
定理（Theorem）系统中的主要结论，通常是经过严格推理和证明的重要结果。
推论（Corollary）某个定理的直接或明显的推论，通常不需复杂证明。
注解（Remark）对前面定义、定理的补充说明、解释或启发性描述。
例子（Example）用于具体说明抽象概念、定理等的实例。

下面为这些推理语言元素分别举个例子。

皮亚诺公理是意大利皮亚诺所构造的算术公理系统中的公理。1889年，在数学家戴德金工作的基础上，皮亚诺在《用一种新方法陈述的算术原理》一书中提出了一个算术公理系统，这个公理系统有九条公理，五条是刻画数的。意大利数学家朱塞佩·皮亚诺提出的关于自然数的五条公理系统。根据这五条公理可以建立起一阶算术系统，也称皮亚诺算术系统。

#axiom()[$0$ 是一个自然数，且 $S(n)=n+1$ ，那么，对任意 $𝑛∈𝑁$ 都有 $S(n)∈N$。这条公理也被称为皮亚诺公理（Peano Axioms）]

下面给出平方根运算（square root）的定义。可以用精确定义的数学语言进行刻画，主要在实数集（或扩展到复数集）中定义。这是从实数完备性（Dedekind 完全性）角度给出的定义，适用于实数构造体系中（如戴德金分割或柯西列构造）。

#definition()[对于 $x∈R$ 且 $x≥0$，若存在 $y∈R$ 满足：
  $
    y^2 = x, y ≥0
  $
  则称 $y$ 为 $x$ 的平方根，记作：
  $
    y=sqrt(x)
  $
  即：
  $
    sqrt(x) = sup{r ∈ QQ | r^2 ≤ x}
  $
]

我们再给出 δ-ε 极限定义。

#definition()[
  函数 $f(x)$ 在 $x arrow c$ 处的极限为 $L$，写作 $lim_(x arrow c) f(x) = L$，其 δ-ε 定义如下：

  对于任意 $epsilon > 0$，存在 $delta > 0$，使得当 $0 < |x - c| < delta$ 时，恒有 $|f(x) - L| < epsilon$。这里的 $epsilon$ 表示任意小的正数，$delta$ 表示 $x$ 与 $c$ 的距离。
]

下面给出函数的一直连续性的命题。该命题是Heine–Cantor 定理的一个特例，其成立依赖于闭区间 $[a,b]$ 的紧性（即紧致性）。实数连续函数在紧致集合上总是一致连续的，这是很多分析定理的基础。

#proposition()[
  设函数 $f: [a, b] arrow RR$ 在闭区间 $[a, b]$ 上连续，
  则 $f$ 在该区间上一致连续。

  换句话说，对任意 $ε > 0$，存在 $delta > 0$，
  对所有 $x, y in [a, b]$，只要满足 $abs(x - y) < delta$，
  就有：
  $
    |f(x) - f(y)| < ε
  $
]


=== 算法的说明

算法可以按照以下的表格方式列出步骤并描述。描述步骤时，可以使用形式化语言或者为代码的形式进行描述。

#algorithm((
  title: "冒泡排序(升序数组)",
  input: [长度为 $n$ 的无序数组 $A = [a_1, a_2, dots, a_n]$],
  output: [按升序排列的数组 $A$],
))[
  1. 初始化 $n = "length"(A)$
  2. *for* $i = 1$ *to* $n - 1$ *do*
  3. *for* $j = 1$ *to* $n - i$ *do*
  4. *if* $A_j > A_(j+1)$ *then*
  5. 交换 $A_j$ 和 $A_(j+1)$
  6. *end if*
  7. *end for*
  8. *end for*
]

== 本文研究内容

在撰写学术论文时，“本文研究内容”这一部分通常位于引言之后，是整个论文结构中的关键组成部分之一。它的主要功能是：

- 明确研究对象与范围；
- 梳理研究目标与问题；
- 描述具体的研究内容、步骤、方法；
- 为下文的章节结构做铺垫。

编写这一部分，首先要注意逻辑清晰，条理分明地描述“做了什么”而非“打算做什么”。再者，语言简洁有力。用学术表达方式（如“提出”“验证”“构建”“分析”等动词）来体现贡献与内容。其次，避免重复引言，不再展开“为什么研究这个”，而要聚焦“研究了什么”。且与章节结构一致 内容描述应与后续各章主题一致，避免前后不符。最后，适度展开即可，一般 300～800 字为宜，避免赘述每个技术细节。以下给出一段简要的范文：

随着人工智能技术的飞速发展，图神经网络（Graph Neural Networks, GNNs）作为一种能够有效建模非欧式数据结构的深度学习框架，已在社交网络分析、知识图谱补全、推荐系统等多个领域取得了显著成果。然而，当前主流的图神经网络方法仍面临诸多挑战，例如节点表示的过度平滑、远距离信息传播效率低、训练数据稀疏性高等问题，限制了其在实际复杂任务中的应用效果。因此，本文围绕“提高图神经网络在推荐系统中对高阶关系建模能力”这一核心问题展开研究，力图提出一种有效、可扩展的解决方案。

本文的研究内容主要包括以下几个方面：

1. 图结构推荐问题建模与分析。首先，本文对推荐系统中用户-物品交互行为进行了图建模，构建了基于二部图的用户-物品图结构，系统分析了高阶邻居在增强节点表示方面的作用机制。同时，结合图谱稀疏性与交互不均衡性问题，提出了面向推荐任务的特征传播框架。

2. 改进型图神经协同过滤模型的设计。针对传统 GCN 架构中节点表示容易出现过度平滑、信息冗余的问题，本文设计了一种改进型的图神经协同过滤模型（Improved Neural Graph Collaborative Filtering, INGCF），该模型引入层间残差机制与加权聚合策略，以提升不同层特征信息的表达力。此外，模型采用可学习的注意力机制，以更有效地控制邻居节点对目标节点表示的影响权重。

3. 模型训练优化与泛化能力提升方法。为了增强模型在数据稀疏场景下的鲁棒性，本文引入了 DropEdge 技术对训练图结构进行随机裁剪，有效缓解图过拟合现象。同时，在损失函数中加入交互对比学习项，提升模型对边界样本的判别能力。优化过程中采用基于自适应学习率的 AdamW 算法，并通过早停策略提升训练效率。

4. 实验设计与效果评估。本文在多个真实公开数据集（如 MovieLens-1M、Amazon-Book、Yelp2018）上开展了充分的实验对比。通过与主流基线模型（如 NGCF、LightGCN、SGL 等）在 Hit\@K、NDCG\@K 等指标上的对比，验证了所提出模型在推荐准确性、稳定性和收敛速度方面的优越性。同时，对模型在不同用户冷启动、边密度、层深度等条件下的表现进行了深入分析。

5. 拓展研究与实际应用探索。在理论模型构建的基础上，本文进一步探索了所提出方法在个性化推荐、知识图谱补全等任务中的泛化能力，并设计了一个原型系统用于展示算法在实际推荐平台中的可行性与部署效果。最后，本文还对当前研究中存在的不足和未来可拓展的研究方向（如动态图建模、多模态特征融合等）进行了展望。

== 附录

在硕士学位论文中，附录是对正文内容的重要补充，主要用于呈现那些与研究密切相关但不宜直接置于正文中的材料。它的存在使得论文内容更加完整、透明，有助于读者深入理解研究的过程与细节。附录通常包括原始数据、问卷样本、访谈记录、程序代码、算法推导过程、模型参数说明等，这些材料虽然不参与正文的论证结构，但却是支撑研究结论的重要基础。

例如，在教育学或社会学等领域的实证研究中，完整的调查问卷、访谈提纲和对话记录往往篇幅较长，不适合直接插入正文，但它们对于验证研究方法的科学性和研究结果的可靠性至关重要。同样，对于计算机、数学等技术类专业，附录中所列出的核心算法源码或计算公式的推导过程，则能体现作者在研究中所进行的实质性技术实现和理论支撑。这些内容不仅展示了研究的细节和深度，也为其他学者提供了可重复、可验证的依据，增强了论文的学术价值与参考意义。

附录的写作应保持与正文一致的学术风格，内容真实、详尽，所列材料须确实与论文研究相关，避免堆砌无关内容或为了充实篇幅而泛泛附加。同时，作者应在正文中适当处提及附录材料，使其成为论文有机的一部分，而非孤立存在。通过附录的设置，作者既能减轻正文的冗余负担，又能使论文整体结构更为清晰严谨，体现出较高的科研规范与写作素养。

== 论文结构安排

本文结构安排如下：第 1 章介绍研究背景与研究意义，梳理国内外相关研究进展与存在的问题；第 2 章对图推荐问题进行建模与理论分析；第 3 章提出改进型图神经协同过滤模型并给出其数学表达与实现机制；第 4 章介绍模型训练方法及实验设计；第 5 章展示实验结果并开展多角度分析与讨论；第 6 章总结全文的研究成果，提出后续研究计划与可能的应用方向。
